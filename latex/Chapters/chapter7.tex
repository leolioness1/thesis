\typeout{NT FILE chapter7.tex}
\chapter{Conclusions and Future Work}
\section{Conclusions}
\paragraph{}
% Research Questions
Two models trained on different datasets were fine-tuned and evaluated in this project, during this process there were several conclusions made:
\begin{enumerate}
    \item{Despite the challenges of data extraction and preprocessing, once a script is in place that does this processing in a semi-automatic way it is relatively easy to improve it. The challenge comes in the time required to understand the open-source \gls{API}s one can access the data through and the format of that data. For example, GeoTiff files are not as common as JPEG or PNG files, so there is a certain level of upskilling and understanding of these different files.}
    
    \item{Changing input parameters has a great impact on the performance of the model. For example, it was seen that the patch size was a very important hyperparameter in the improvement of the model performance. The improvement in performance came from getting the right balance between background (non-\gls{RTS}) pixels and foreground (\gls{RTS}) pixels without losing too much context.}
    
    \item{Satisfactory results were achieved with 10-meter resolution images for the identification of thaw slumps. For a more valuable task of monitoring the changes in \gls{RTS}, however, the model could benefit from higher resolution images, as the change may be less than \SI{10}{\metre} and therefore be hard to track. It could also help improve the performance on smaller \gls{RTS} or those with more intricate shapes, as it would provide a more detailed view.}
    
    \item{All the points above put a great emphasis on the input data. For this project, the importance of having the correct data collected and preprocessed in the right way is essential for the successful performance of the model. In hindsight, this author would have spent more time getting this step correct to avoid having to backtrack to get more data halfway through the project.}
    
    \item{Learning rate and batch size hyperparameters are some of the most important hyperparameters to tune in a model. This together with the correct regularisation strategy to prevent overfitting were some of the most important aspects found when conducting experiments.}
\end{enumerate}

\section{Limitations}
\paragraph{}
The data extraction part of the project came with many limitations. The dependency on third-party tools to extract data led to a small dataset to work with, given the limited time constraints, it was hard to focus on a more automated process for data extraction.

The \gls{GEE} and JavaScript data extraction method introduced bias and potentially a misalignment between the input data and the mask.  This was addressed by the second batch of data extraction, where \gls{JP2} tiles were extracted directly and processed into 64x64 windows. This allowed for debiased images and larger sample size to work with, improving generalisation.

Since this model was only trained on tiles containing positive labels, it does not know how to identify tiles with no thaw slumps, which is an important characteristic when performing inference across the Arctic. 

No model architecture hyperparameter tuning was made, that is the number of filters, kernel size, padding type, stride, pooling stride, type of pooling were not optimised and other model architectures were not evaluated, so potentially the solution presented may not be the most efficient or the network might be too deep for the problem at hand.

\section{Future Work}
\paragraph{}
In the future, an approach that aims to measure the change in \gls{RTS}s through time, like in Huang et al.'s latest paper (\cite{HUANG2021102399}) would be more beneficial to the problem this project aims to address. This increases the complexity of the task at hand because it introduces an additional dimension of time and its sequence, however it provides better means for estimation and prediction of permafrost thaw year on year.

It would also be beneficial to try different architecture parameters such as filter size and kernel size or even other architectures such as DeepLab v3+ or \gls{FCN} and assess the impact on the model performance.

To improve the generalisation of the model, a wider research area, not limited to the sites where labels were provided, should be covered so that the model can be used in other geographical characteristics.

Given more time, there are considerations on model inference time, throughput and size that could be improved by simplifying the U-Net model to a simpler model architecture. This could be useful, if the model were to be used in edge devices or applications that require low latency.

The use of Bayesian optimisation techniques or even Constraint Active Search (\cite{pmlr-v139-malkomes21a}) to perform hyperparameter tuning rather than using Random Search techniques, would likely lead to better model optimisation without the time-consuming experiment set up presented in Chapter \ref{experiments_chapter}.

In the future, the model could be trained on higher resolution images such as those available through Planet data (\SI{3}{\metre} resolution) to evaluate how it affects model performance, especially when dealing with smaller  \gls{RTS} and those with more complex shapes.

To increase model performance on tiles with a small number or no \gls{RTS}  at all, the model should be trained on a balanced dataset of tiles containing thaw slumps, as well as some not containing any.